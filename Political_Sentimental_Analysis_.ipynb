{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1uetrtrV_2ny-apRzqH3JpetA6r3rV9Jo",
      "authorship_tag": "ABX9TyMWfVIMYvEx4pz6tKnizH3W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dharunika-07/Political_sentiment_analysis/blob/main/Political_Sentimental_Analysis_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load the dataset\n",
        "train_data = pd.read_csv('/content/drive/MyDrive/train_data.csv')\n",
        "# Debugging: Check the data structure\n",
        "print(\"Train Data Head:\\n\", train_data.head())\n",
        "\n",
        "# Preprocess text: Remove special characters and convert to lowercase\n",
        "def preprocess_text(text):\n",
        "    text = str(text).lower()  # Convert to lowercase\n",
        "    text = text.replace(r\"[^\\w\\s]\", \"\")  # Remove special characters\n",
        "    return text\n",
        "\n",
        "# Apply preprocessing to the dataset\n",
        "train_data['content'] = train_data['content'].apply(preprocess_text)\n",
        "\n",
        "# Split data into features (X) and labels (y)\n",
        "X = train_data['content']\n",
        "y = train_data['labels']\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert text data to numerical data using CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_vect = vectorizer.fit_transform(X_train)\n",
        "X_test_vect = vectorizer.transform(X_test)\n",
        "\n",
        "# Train the Naive Bayes model\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train_vect, y_train)\n",
        "\n",
        "# Predict sentiments for the test data\n",
        "y_pred = model.predict(X_test_vect)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Predict sentiments for the entire dataset\n",
        "test_data = pd.read_csv('/content/drive/MyDrive/test_data.csv')  # Replace with your actual test dataset file\n",
        "test_data['content'] = test_data['content'].apply(preprocess_text)\n",
        "X_test_full = vectorizer.transform(test_data['content'])\n",
        "predicted_labels = model.predict(X_test_full)\n",
        "\n",
        "# Add predictions to test dataset\n",
        "test_data['predicted_labels'] = predicted_labels\n",
        "\n",
        "# Save predictions to a new CSV file\n",
        "output_file = 'sentiment_predictions_nb.csv'\n",
        "test_data[['content', 'predicted_labels']].to_csv(output_file, index=False, encoding='utf-8-sig')\n",
        "print(f\"Predictions saved to {output_file}\")\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "id": "_lcCt7ucGYhj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9873c4db-aef6-41a9-aaf3-a06aa37d6cbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Data Head:\n",
            "                                              content         labels\n",
            "0  родрпЖройрпНроХро╛роЪро┐ родрпКроХрпБродро┐ рокрпБродро┐роп родрооро┐ро┤роХроорпН роХроЯрпНроЪро┐ ро╡рпЗроЯрпНрокро╛ро│ро░рпН ...        Neutral\n",
            "1  роЕрогрпНрогройрпН роЗродройрпИ роЪрпВроЪроХрооро╛роХ 11 рооро╛родроЩрпНроХро│рпН роорпБройрпНрокрпЗ рокрпЗроЯрпНроЯро┐роп...  Substantiated\n",
            "2  роТро░рпБ ро╡ро░рпБроЯроорпН роЖроХро┐ ро╡ро┐роЯрпНроЯродрпБ роЗроирпНрод родрпБропро░роорпН роирпЗро░рпНроирпНродрпБ......    Opinionated\n",
            "3  роОроЯрокрпНрокро╛роЯро┐ропрпИ роХрогрпНроЯрпБроХрпКро│рпНро│ро╛род \"роОроЯрокрпНрокро╛роЯро┐\"ЁЯлв\\n ---\\nроЖродро░...       Positive\n",
            "4  роОроЩрпНроХро│ро┐ройрпН роЕро░роЪро┐ропро▓рпН роЕроЯрпБродрпНрод родро▓рпИроорпБро▒рпИроХрпНроХрпБрооро╛ройродрпБ \\n#роороХ...    Opinionated\n",
            "Accuracy: 0.31\n",
            "Classification Report:\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "         Negative       0.15      0.02      0.04        82\n",
            "          Neutral       0.17      0.15      0.16       117\n",
            "None of the above       1.00      0.08      0.15        37\n",
            "      Opinionated       0.35      0.63      0.45       282\n",
            "         Positive       0.28      0.27      0.27       120\n",
            "        Sarcastic       0.33      0.22      0.26       159\n",
            "    Substantiated       0.18      0.05      0.08        74\n",
            "\n",
            "         accuracy                           0.31       871\n",
            "        macro avg       0.35      0.20      0.20       871\n",
            "     weighted avg       0.31      0.31      0.27       871\n",
            "\n",
            "Predictions saved to sentiment_predictions_nb.csv\n",
            "Accuracy: 0.31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "kM786QEJPqwC"
      }
    }
  ]
}