{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dharunika-07/Political_sentiment_analysis/blob/main/Sentiment_analysis_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duyxZceEE9TB",
        "outputId": "85e1df67-98ca-4baf-ea75-0e6ccc07de5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (3.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.1.24)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras) (0.14.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.55.6)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow keras numpy pandas matplotlib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1HGnmrwrHMsI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, SpatialDropout1D\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFbVFo_IMzI4",
        "outputId": "56821661-3d3a-4828-e59a-6251c983ba79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qdxp0B_0HVHj",
        "outputId": "0714902c-4ab8-422e-de5f-5bb1d541f2bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             content         labels\n",
            "0  à®¤à¯†à®©à¯à®•à®¾à®šà®¿ à®¤à¯Šà®•à¯à®¤à®¿ à®ªà¯à®¤à®¿à®¯ à®¤à®®à®¿à®´à®•à®®à¯ à®•à®Ÿà¯à®šà®¿ à®µà¯‡à®Ÿà¯à®ªà®¾à®³à®°à¯ ...        Neutral\n",
            "1  à®…à®£à¯à®£à®©à¯ à®‡à®¤à®©à¯ˆ à®šà¯‚à®šà®•à®®à®¾à®• 11 à®®à®¾à®¤à®™à¯à®•à®³à¯ à®®à¯à®©à¯à®ªà¯‡ à®ªà¯‡à®Ÿà¯à®Ÿà®¿à®¯...  Substantiated\n",
            "2  à®’à®°à¯ à®µà®°à¯à®Ÿà®®à¯ à®†à®•à®¿ à®µà®¿à®Ÿà¯à®Ÿà®¤à¯ à®‡à®¨à¯à®¤ à®¤à¯à®¯à®°à®®à¯ à®¨à¯‡à®°à¯à®¨à¯à®¤à¯......    Opinionated\n",
            "3  à®à®Ÿà®ªà¯à®ªà®¾à®Ÿà®¿à®¯à¯ˆ à®•à®£à¯à®Ÿà¯à®•à¯Šà®³à¯à®³à®¾à®¤ \"à®à®Ÿà®ªà¯à®ªà®¾à®Ÿà®¿\"ğŸ«¢\\n ---\\nà®†à®¤à®°...       Positive\n",
            "4  à®à®™à¯à®•à®³à®¿à®©à¯ à®…à®°à®šà®¿à®¯à®²à¯ à®…à®Ÿà¯à®¤à¯à®¤ à®¤à®²à¯ˆà®®à¯à®±à¯ˆà®•à¯à®•à¯à®®à®¾à®©à®¤à¯ \\n#à®®à®•...    Opinionated\n",
            "      Id                                            content\n",
            "0  PS_01  à®‡à®¸à¯à®²à®¾à®®à®¿à®¯ à®šà®•à¯‹à®¤à®°à®°à¯à®•à®³à¯à®Ÿà®©à¯ à®°à®®à®²à®¾à®©à¯ à®•à¯Šà®£à¯à®Ÿà®¾à®Ÿà®¿à®¯ à®…à®¤à®¿à®®à¯à®•...\n",
            "1  PS_02  \\nà®“à®ªà®¿à®à®¸à¯ - à®à®Ÿà®ªà¯à®ªà®¾à®Ÿà®¿ à®ªà¯‹à®Ÿà¯à®Ÿà®¾ à®ªà¯‹à®Ÿà¯à®Ÿà®¿! à®¤à®¿à®Ÿà¯€à®°à¯†à®© à®ªà®£à®¿...\n",
            "2  PS_03  à®‡à®©à¯à®±à¯ˆà®¯ à®ªà®°à®ªà¯à®ªà¯à®°à¯ˆ:\\n\\nà®¨à®¾à®®à¯ à®¤à®®à®¿à®´à®°à¯ à®•à®Ÿà¯à®šà®¿ à®¤à®²à¯ˆà®®à¯ˆ à®’à®°...\n",
            "3  PS_04  ğŸ‡°ğŸ‡¬ğŸ™ï¸ à®‡à®©à¯à®©à¯à®®à¯ 05 à® à®¨à®¾à®³à®¿à®²à¯, à®µà¯†à®²à¯à®µà¯‹à®®à¯ à®¤à®®à®¿à®´à®°à®¾à®¯à¯ - ...\n",
            "4  PS_05  à®Ÿà®¾à®¸à¯à®®à®¾à®•à¯à®² à®®à®Ÿà¯à®Ÿà¯à®®à¯à®¤à®¾à®©à¯ à®•à®°à¯à®£à®¾à®¨à®¿à®¤à®¿ à®…à®µà®°à¯à®•à®³à®¿à®©à¯  à®ªà¯†à®¯...\n"
          ]
        }
      ],
      "source": [
        "train_df = pd.read_csv(\"/content/drive/MyDrive/PS_train.csv\")  # Replace with your train file\n",
        "test_df = pd.read_csv(\"/content/drive/MyDrive/PS_test_without_lables.csv\")  # Replace with your test file\n",
        "print(train_df.head())\n",
        "print(test_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "pG_8gp3GQiKt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f525d1d7-dd9f-40c3-8c6f-155e9e5a7a98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0               Neutral\n",
            "1         Substantiated\n",
            "2           Opinionated\n",
            "3              Positive\n",
            "4           Opinionated\n",
            "5         Substantiated\n",
            "6         Substantiated\n",
            "7              Positive\n",
            "8              Positive\n",
            "9           Opinionated\n",
            "10          Opinionated\n",
            "11            Sarcastic\n",
            "12          Opinionated\n",
            "13             Positive\n",
            "14            Sarcastic\n",
            "15             Negative\n",
            "16              Neutral\n",
            "17            Sarcastic\n",
            "18        Substantiated\n",
            "19              Neutral\n",
            "20              Neutral\n",
            "21    None of the above\n",
            "22          Opinionated\n",
            "23              Neutral\n",
            "24          Opinionated\n",
            "25        Substantiated\n",
            "26             Negative\n",
            "27            Sarcastic\n",
            "28            Sarcastic\n",
            "29            Sarcastic\n",
            "Name: labels, dtype: object\n",
            "y:  [1 6 3 4 3 6 6 4 4 3 3 5 3 4 5 0 1 5 6 1 1 2 3 1 3 6 0 5 5 5]\n"
          ]
        }
      ],
      "source": [
        "X = train_df['content']  # Replace 'text' with the column containing Tamil text\n",
        "y = train_df['labels']  # Replace 'label' with the column containing sentiment labels\n",
        "\n",
        "# Encode labels\n",
        "encoder = LabelEncoder()\n",
        "y = encoder.fit_transform(y)\n",
        "print(train_df['labels'].head(30))\n",
        "print(\"y: \",y[0:30])\n",
        "# Split into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wse3KS92RmUY"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(num_words=5000, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_val)\n",
        "\n",
        "max_len = 50  # Maximum length of sequences\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len, padding='post', truncating='post')\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len, padding='post', truncating='post')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "1qWqruflRymN",
        "outputId": "0d0d067c-b8a2-4f01-cd26-dd6e337c8b7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                â”‚ ?                           â”‚     \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ spatial_dropout1d (\u001b[38;5;33mSpatialDropout1D\u001b[0m) â”‚ ?                           â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          â”‚ ?                           â”‚     \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                        â”‚ ?                           â”‚     \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)                    â”‚ ?                           â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      â”‚ ?                           â”‚     \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                         </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape                </span>â”ƒ<span style=\"font-weight: bold\">         Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                â”‚ ?                           â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ spatial_dropout1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>) â”‚ ?                           â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          â”‚ ?                           â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        â”‚ ?                           â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    â”‚ ?                           â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      â”‚ ?                           â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model = Sequential([\n",
        "    Embedding(input_dim=5000, output_dim=128, input_length=max_len),\n",
        "    SpatialDropout1D(0.2),\n",
        "    LSTM(128, dropout=0.2, recurrent_dropout=0.2),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(3, activation='softmax')  # 3 classes: Negative, Neutral, Positive\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tRkX5g9DcDD",
        "outputId": "fdb09ba2-51f4-4083-8a81-9ba400ed0460"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_val shape after reshape: (871,)\n"
          ]
        }
      ],
      "source": [
        "y_val = y_val.reshape(-1)\n",
        "print(\"y_val shape after reshape:\", y_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYVM0mlYSi-s",
        "outputId": "a504c96f-926c-4c73-b41a-7bfb7de2d4dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test_pad dtype: int32\n",
            "y_val dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Convert to NumPy arrays if needed\n",
        "X_test_pad = np.array(X_test_pad)\n",
        "y_val = np.array(y_val)\n",
        "\n",
        "# Check data types\n",
        "print(\"X_test_pad dtype:\", X_test_pad.dtype)\n",
        "print(\"y_val dtype:\", y_val.dtype)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-QK15DfIA1a",
        "outputId": "c153a6cc-dd38-4e79-9325-4f2aa1fb8169"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_val shape: (871,)\n"
          ]
        }
      ],
      "source": [
        "if len(y_val.shape) > 1:\n",
        "    y_val = y_val.reshape(-1)  # Flatten to 1D\n",
        "print(\"y_val shape:\", y_val.shape)\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Ensure consistent padding\n",
        "X_test_pad = pad_sequences(X_test_pad, maxlen=50, padding='post', truncating='post')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75KlPozuJm2K",
        "outputId": "4c81edf5-ec20-4865-de9e-91c5ba114faf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique values in y_train: {0, 1, 2, 3, 4, 5, 6}\n",
            "Unique values in y_val: {0, 1, 2, 3, 4, 5, 6}\n",
            "Unique values in y_train after encoding: {0, 1, 2, 3, 4, 5, 6}\n",
            "Unique values in y_val after encoding: {0, 1, 2, 3, 4, 5, 6}\n"
          ]
        }
      ],
      "source": [
        "print(\"Unique values in y_train:\", set(y_train))\n",
        "print(\"Unique values in y_val:\", set(y_val))\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Fit encoder on all labels in training and validation sets\n",
        "encoder = LabelEncoder()\n",
        "y_train = encoder.fit_transform(y_train)\n",
        "y_val = encoder.transform(y_val)\n",
        "\n",
        "# Check the unique labels after encoding\n",
        "print(\"Unique values in y_train after encoding:\", set(y_train))\n",
        "print(\"Unique values in y_val after encoding:\", set(y_val))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUIhA50KJ5Se",
        "outputId": "5f03820f-092e-4711-a2ed-487b8153e386"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "\n",
        "num_classes = len(set(y_train))  # Dynamically determine number of classes\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=1000, output_dim=128, input_length=50),\n",
        "    LSTM(128),\n",
        "    Dense(num_classes, activation='softmax')  # Adjust num_classes here\n",
        "])\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YM_NsPCbKi9K",
        "outputId": "75e80b89-0cf7-41c6-8d60-ab547f7322e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max value in X_train_pad: 4999\n",
            "Min value in X_train_pad: 0\n",
            "Max value in X_test_pad: 4996\n",
            "Min value in X_test_pad: 0\n",
            "Max value in X_train_pad after fix: 999\n",
            "Max value in X_test_pad after fix: 999\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Check the maximum and minimum values in your data\n",
        "print(\"Max value in X_train_pad:\", np.max(X_train_pad))\n",
        "print(\"Min value in X_train_pad:\", np.min(X_train_pad))\n",
        "print(\"Max value in X_test_pad:\", np.max(X_test_pad))\n",
        "print(\"Min value in X_test_pad:\", np.min(X_test_pad))\n",
        "\n",
        "input_dim = np.max(X_train_pad) + 1  # Set input_dim to max index + 1\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=input_dim, output_dim=128, input_length=50),\n",
        "    LSTM(128),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Clip values to be within the valid range\n",
        "X_train_pad = np.clip(X_train_pad, 0, 999)\n",
        "X_test_pad = np.clip(X_test_pad, 0, 999)\n",
        "\n",
        "print(\"Max value in X_train_pad after fix:\", np.max(X_train_pad))\n",
        "print(\"Max value in X_test_pad after fix:\", np.max(X_test_pad))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUwEPGplR-H5",
        "outputId": "0e4c9074-f260-4f73-9244-65dc496802d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m109/109\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 105ms/step - accuracy: 0.2942 - loss: 1.8343 - val_accuracy: 0.3238 - val_loss: 1.7930\n",
            "Epoch 2/10\n",
            "\u001b[1m109/109\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 81ms/step - accuracy: 0.3057 - loss: 1.8122 - val_accuracy: 0.3238 - val_loss: 1.7914\n",
            "Epoch 3/10\n",
            "\u001b[1m109/109\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 94ms/step - accuracy: 0.2976 - loss: 1.8173 - val_accuracy: 0.3238 - val_loss: 1.7877\n",
            "Epoch 4/10\n",
            "\u001b[1m109/109\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 102ms/step - accuracy: 0.3014 - loss: 1.8065 - val_accuracy: 0.3238 - val_loss: 1.7863\n",
            "Epoch 5/10\n",
            "\u001b[1m109/109\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 103ms/step - accuracy: 0.3077 - loss: 1.7999 - val_accuracy: 0.3238 - val_loss: 1.7891\n",
            "Epoch 6/10\n",
            "\u001b[1m109/109\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 91ms/step - accuracy: 0.3049 - loss: 1.7971 - val_accuracy: 0.3238 - val_loss: 1.7888\n",
            "Epoch 7/10\n",
            "\u001b[1m109/109\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 91ms/step - accuracy: 0.3110 - loss: 1.7952 - val_accuracy: 0.3238 - val_loss: 1.7879\n",
            "Epoch 8/10\n",
            "\u001b[1m109/109\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 102ms/step - accuracy: 0.3155 - loss: 1.7957 - val_accuracy: 0.3192 - val_loss: 1.7901\n",
            "Epoch 9/10\n",
            "\u001b[1m109/109\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 102ms/step - accuracy: 0.3086 - loss: 1.7782 - val_accuracy: 0.3249 - val_loss: 1.7656\n",
            "Epoch 10/10\n",
            "\u001b[1m109/109\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 103ms/step - accuracy: 0.3132 - loss: 1.7646 - val_accuracy: 0.3238 - val_loss: 1.7354\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    X_train_pad, y_train,\n",
        "    validation_data=(X_test_pad, y_val),\n",
        "    epochs=10,\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "\n",
        "# Split the data into 80% training and 20% validation\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_pad, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Check the max and min values in training data\n",
        "print(\"Max value in X_train:\", np.max(X_train))\n",
        "print(\"Min value in X_train:\", np.min(X_train))\n",
        "print(\"Max value in X_val:\", np.max(X_val))\n",
        "print(\"Min value in X_val:\", np.min(X_val))\n",
        "\n",
        "# Define input dimension\n",
        "input_dim = np.max(X_train) + 1  # Set input_dim to max index + 1\n",
        "\n",
        "# Define the model\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=input_dim, output_dim=128, input_length=50),\n",
        "    LSTM(128),\n",
        "    Dense(len(set(y_train)), activation='softmax')  # Ensure correct number of output classes\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Clip values to be within a valid range\n",
        "X_train = np.clip(X_train, 0, 999)\n",
        "X_val = np.clip(X_val, 0, 999)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=32, verbose=1)\n",
        "\n",
        "# Predict on validation data\n",
        "y_val_pred_probs = model.predict(X_val)\n",
        "y_val_pred = np.argmax(y_val_pred_probs, axis=1)  # Convert probabilities to class labels\n",
        "\n",
        "# Compute accuracy\n",
        "accuracy = accuracy_score(y_val, y_val_pred)\n",
        "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Compute F1-score\n",
        "print(\"Classification Report:\\n\", classification_report(y_val, y_val_pred, digits=4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGhXb6FG_qO-",
        "outputId": "64f88c62-9dfb-454e-dc19-18c81a3d7a41"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max value in X_train: 999\n",
            "Min value in X_train: 0\n",
            "Max value in X_val: 999\n",
            "Min value in X_val: 0\n",
            "Epoch 1/10\n",
            "\u001b[1m87/87\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 96ms/step - accuracy: 0.2886 - loss: 1.8415 - val_accuracy: 0.2999 - val_loss: 1.8009\n",
            "Epoch 2/10\n",
            "\u001b[1m87/87\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - accuracy: 0.3257 - loss: 1.7901 - val_accuracy: 0.2999 - val_loss: 1.8089\n",
            "Epoch 3/10\n",
            "\u001b[1m87/87\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 105ms/step - accuracy: 0.3214 - loss: 1.7861 - val_accuracy: 0.2999 - val_loss: 1.7990\n",
            "Epoch 4/10\n",
            "\u001b[1m87/87\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.3090 - loss: 1.8015 - val_accuracy: 0.2999 - val_loss: 1.8077\n",
            "Epoch 5/10\n",
            "\u001b[1m87/87\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 84ms/step - accuracy: 0.3155 - loss: 1.8027 - val_accuracy: 0.2999 - val_loss: 1.8028\n",
            "Epoch 6/10\n",
            "\u001b[1m87/87\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 106ms/step - accuracy: 0.3121 - loss: 1.7979 - val_accuracy: 0.2984 - val_loss: 1.8167\n",
            "Epoch 7/10\n",
            "\u001b[1m87/87\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.3167 - loss: 1.7853 - val_accuracy: 0.3013 - val_loss: 1.7716\n",
            "Epoch 8/10\n",
            "\u001b[1m87/87\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 95ms/step - accuracy: 0.3246 - loss: 1.7224 - val_accuracy: 0.3156 - val_loss: 1.7246\n",
            "Epoch 9/10\n",
            "\u001b[1m87/87\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 112ms/step - accuracy: 0.3404 - loss: 1.6762 - val_accuracy: 0.3286 - val_loss: 1.7226\n",
            "Epoch 10/10\n",
            "\u001b[1m87/87\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.3424 - loss: 1.6475 - val_accuracy: 0.3056 - val_loss: 1.7311\n",
            "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step\n",
            "Validation Accuracy: 0.3056\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.0000    0.0000    0.0000        67\n",
            "           1     0.0000    0.0000    0.0000        82\n",
            "           2     0.0000    0.0000    0.0000        28\n",
            "           3     0.3299    0.7656    0.4611       209\n",
            "           4     0.1935    0.1237    0.1509        97\n",
            "           5     0.2759    0.2685    0.2721       149\n",
            "           6     0.2000    0.0154    0.0286        65\n",
            "\n",
            "    accuracy                         0.3056       697\n",
            "   macro avg     0.1428    0.1676    0.1304       697\n",
            "weighted avg     0.2035    0.3056    0.2201       697\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Load the test data (ensure it contains the 'content' and 'labels' columns)\n",
        "test_df = pd.read_csv(\"/content/drive/MyDrive/PS_test.csv\")\n",
        "\n",
        "# Extract the text and labels\n",
        "X_test = test_df['content'].values\n",
        "y_test = test_df['labels'].values  # Actual labels from the test set\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "y_test = encoder.fit_transform(y_test)\n",
        "print(train_df['labels'].head(30))\n",
        "print(\"y: \",y_test[0:30])\n",
        "# Split into training and validation sets\n",
        "#X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert labels to numerical values using the same encoder\n",
        "#y_test = encoder.transform(y_test)\n",
        "\n",
        "# Tokenize and pad test data\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=50, padding='post', truncating='post')\n",
        "\n",
        "# Clip values to be within valid range\n",
        "X_test_pad = np.clip(X_test_pad, 0, 999)\n",
        "\n",
        "# Predict on the test data\n",
        "y_test_pred_probs = model.predict(X_test_pad)\n",
        "y_test_pred = np.argmax(y_test_pred_probs, axis=1)  # Convert probabilities to class labels\n",
        "\n",
        "# Compute accuracy\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "# Compute F1-score\n",
        "print(\"Test Classification Report:\\n\", classification_report(y_test, y_test_pred, digits=4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTOmTcGyAQ4m",
        "outputId": "e874ea14-a822-413b-eff4-739472f0c42a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0               Neutral\n",
            "1         Substantiated\n",
            "2           Opinionated\n",
            "3              Positive\n",
            "4           Opinionated\n",
            "5         Substantiated\n",
            "6         Substantiated\n",
            "7              Positive\n",
            "8              Positive\n",
            "9           Opinionated\n",
            "10          Opinionated\n",
            "11            Sarcastic\n",
            "12          Opinionated\n",
            "13             Positive\n",
            "14            Sarcastic\n",
            "15             Negative\n",
            "16              Neutral\n",
            "17            Sarcastic\n",
            "18        Substantiated\n",
            "19              Neutral\n",
            "20              Neutral\n",
            "21    None of the above\n",
            "22          Opinionated\n",
            "23              Neutral\n",
            "24          Opinionated\n",
            "25        Substantiated\n",
            "26             Negative\n",
            "27            Sarcastic\n",
            "28            Sarcastic\n",
            "29            Sarcastic\n",
            "Name: labels, dtype: object\n",
            "y:  [1 0 6 4 4 3 3 5 2 4 6 3 3 6 3 5 3 1 5 4 1 1 6 5 0 2 3 4 3 0]\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Test Accuracy: 0.3254\n",
            "Test Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.0000    0.0000    0.0000        46\n",
            "           1     0.0000    0.0000    0.0000        70\n",
            "           2     0.0000    0.0000    0.0000        25\n",
            "           3     0.3405    0.7427    0.4669       171\n",
            "           4     0.2889    0.1733    0.2167        75\n",
            "           5     0.2880    0.3396    0.3117       106\n",
            "           6     1.0000    0.0196    0.0385        51\n",
            "\n",
            "    accuracy                         0.3254       544\n",
            "   macro avg     0.2739    0.1822    0.1477       544\n",
            "weighted avg     0.2967    0.3254    0.2410       544\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of X_test_pad:\", X_test_pad.shape)\n",
        "print(\"Number of rows in test_data:\", len(test_data))\n",
        "\n",
        "# Adjust X_test_pad to match the number of rows in test_data\n",
        "X_test_pad = X_test_pad[:len(test_data)]\n",
        "\n",
        "y_pred_probs = model.predict(X_test_pad)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Bipfkat8jPu",
        "outputId": "62cc39ea-3eda-4c44-b45c-296345d73da6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_test_pad: (871, 50)\n",
            "Number of rows in test_data: 544\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Define the mapping from numeric labels to textual descriptions\n",
        "label_mapping = {\n",
        "    0: \"Negative\",\n",
        "    1: \"Neutral\",\n",
        "    2: \"None of the above\",\n",
        "    3: \"Opinionated\",\n",
        "    4: \"Positive\",\n",
        "    5: \"Sarcastic\",\n",
        "    6: \"Substantiated\"\n",
        "}\n",
        "\n",
        "# 1. Load test data\n",
        "test_data = pd.read_csv(\"/content/drive/MyDrive/PS_test_without_lables.csv\")  # Replace with your test data file\n",
        "print(\"Number of rows in test_data:\", len(test_data))\n",
        "\n",
        "# 2. Ensure X_test_pad matches the test data length\n",
        "X_test_pad = X_test_pad[:len(test_data)]\n",
        "print(\"Shape of X_test_pad after adjustment:\", X_test_pad.shape)\n",
        "\n",
        "# 3. Make predictions\n",
        "y_pred_probs = model.predict(X_test_pad)  # Predicted probabilities\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)  # Convert probabilities to class labels\n",
        "\n",
        "# 4. Map numeric labels to textual descriptions\n",
        "y_pred_labels = [label_mapping[label] for label in y_pred]\n",
        "\n",
        "# 5. Add predictions to test_data\n",
        "test_data['Predicted_Label'] = y_pred_labels\n",
        "test_data['Predicted_Probabilities'] = y_pred_probs.tolist()\n",
        "\n",
        "# 6. Save results to CSV\n",
        "output_file = \"/content/drive/MyDrive/PS_test_predictions.csv\"  # Specify the output path\n",
        "test_data.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"Results saved to {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1SL6UKc8xsm",
        "outputId": "d6a14d1a-b993-4334-ce8f-faa9557b355d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows in test_data: 544\n",
            "Shape of X_test_pad after adjustment: (544, 50)\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Results saved to /content/drive/MyDrive/PS_test_predictions.csv\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNOh5khByGgILLA7JunMsxm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}